import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from torch.autograd import grad
import os
import time

class AdaptiveTanh(nn.Module):
    """Layer-wise Locally Adaptive Tanh Activation from the paper"""
    def __init__(self, n=10):
        super().__init__()
        self.n = n
        self.a = nn.Parameter(torch.ones(1)*n)
        
    def forward(self, x):
        return torch.tanh(self.a * x)

class PINN_LMD(nn.Module):
    """Enhanced PINN model matching the paper's specifications"""
    def __init__(self, input_dim=4, hidden_dim=30, output_dim=1):
        super().__init__()
        
        # Input normalization parameters
        self.register_buffer('input_mean', torch.zeros(input_dim))
        self.register_buffer('input_std', torch.ones(input_dim))
        
        # Scaling factors (initialized to 1, will be set later)
        self.register_buffer('k_x', torch.ones(1))
        self.register_buffer('k_t', torch.ones(1))
        self.register_buffer('k_u', torch.ones(1))
        
        # Network architecture
        self.input_layer = nn.Linear(input_dim, hidden_dim)
        
        # Residual block
        self.res_block = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            AdaptiveTanh(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        self.output_layer = nn.Linear(hidden_dim, output_dim)
        
        # Initialize weights
        self._init_weights()
        
    def _init_weights(self):
        # Xavier/Glorot initialization
        nn.init.xavier_normal_(self.input_layer.weight)
        nn.init.zeros_(self.input_layer.bias)
        
        for layer in [self.res_block[0], self.res_block[2]]:
            nn.init.xavier_normal_(layer.weight)
            nn.init.zeros_(layer.bias)
            
        nn.init.xavier_normal_(self.output_layer.weight, gain=0.1)
        nn.init.zeros_(self.output_layer.bias)
        
    def set_scaling_factors(self, Lx, Ly, Lz, t1, t2, T_max):
        """Set scaling factors according to paper's methodology"""
        self.k_x.data = torch.tensor(1.0 / max(Lx, Ly, Lz), dtype=torch.float32)
        self.k_t.data = torch.tensor(1.0 / (t1 + t2), dtype=torch.float32)
        self.k_u.data = torch.tensor(1.0 / T_max, dtype=torch.float32)
        
    def set_input_stats(self, mean, std):
        """Set input normalization statistics"""
        self.input_mean.data.copy_(torch.tensor(mean, dtype=torch.float32))
        self.input_std.data.copy_(torch.tensor(std, dtype=torch.float32))
        
    def forward(self, x):
        # Normalize and scale inputs
        x_norm = (x - self.input_mean) / self.input_std
        x_scaled = torch.cat([
            x_norm[:,:3] * self.k_x,  # x,y,z scaling
            x_norm[:,3:4] * self.k_t  # t scaling
        ], dim=1)
        
        # Forward pass through network
        h = torch.tanh(self.input_layer(x_scaled))
        
        # Residual block
        residual = h
        h = self.res_block(h) + residual
        h = torch.tanh(h)
        
        # Output with sigmoid activation (0-1 range)
        u_scaled = torch.sigmoid(self.output_layer(h))
        
        # Unscale output temperature
        return u_scaled / self.k_u

class LMDPhysics:
    """Physics module implementing all LMD-specific equations"""
    def __init__(self, params):
        self.params = params
        
        # Physical constants
        self.sigma_sb = 5.67e-8  # Stefan-Boltzmann constant
        
        # Domain parameters
        self.Lx = params['Lx']
        self.Ly = params['Ly']
        self.Lz = params['Lz']
        self.t1 = params['t1']
        self.t2 = params['t2']
        
        # Reference values for normalization
        self.Q_max = 5.0e11  # Max laser power density
        self.T_ref = params['T0'] + 2500  # Reference temperature (ambient + max expected)
        
    def thermal_conductivity(self, T):
        """Temperature-dependent thermal conductivity from Table 2"""
        # k(T) = 2.0e-5*T^2 - 0.0441*T + 49.94 (T < 1773.15 K)
        # k(T) = 31.9 (T >= 1773.15 K)
        k_low = 2.0e-5*T**2 - 0.0441*T + 49.94
        k_high = torch.full_like(T, 31.9)
        return torch.where(T < 1773.15, k_low, k_high)
        
    def specific_heat(self, T):
        """Temperature-dependent specific heat from Table 2"""
        # Cp(T) = 1.04e-4*T^2 - 0.3426*T + 314.2 (T < 1773.15 K)
        # Cp(T) = 700 (T >= 1773.15 K)
        cp_low = 1.04e-4*T**2 - 0.3426*T + 314.2
        cp_high = torch.full_like(T, 700.0)
        return torch.where(T < 1773.15, cp_low, cp_high)
        
    def laser_heat_source(self, x, y, z, t):
        """Gaussian laser heat source from Eq. (4)"""
        v = self.params['v']
        P = self.params['P']
        eta = self.params['eta']
        Ra, Rb, Rc = self.params['Ra'], self.params['Rb'], self.params['Rc']
        
        # Laser position (moving along x-axis at y=Ly/2, z=0)
        x0, y0, z0 = 0.0, self.Ly/2, 0.0
        
        # Time-dependent intensity (active only during deposition)
        active = (t <= self.t1).float()
        
        # Ellipsoidal Gaussian from Eq. (4)
        dx = (x - (v*t + x0)) / Ra
        dy = (y - y0) / Rb
        dz = (z - z0) / Rc
        r_sq = dx**2 + dy**2 + dz**2
        
        Q = (6*np.sqrt(3)*eta*P / (np.pi*np.sqrt(np.pi)*Ra*Rb*Rc)) * torch.exp(-3*r_sq) * active
        
        return Q / self.Q_max  # Normalized
    
    def compute_derivatives(self, model, x, y, z, t):
        """Compute all required derivatives using autodiff"""
        # Requires grad for autodiff
        x_t = x.clone().requires_grad_(True)
        y_t = y.clone().requires_grad_(True)
        z_t = z.clone().requires_grad_(True)
        t_t = t.clone().requires_grad_(True)
        
        # Stack inputs and forward pass
        inputs = torch.stack([x_t, y_t, z_t, t_t], dim=1)
        u = model(inputs)
        T = u  # Direct temperature output
        
        # First derivatives
        dT_dx = grad(T, x_t, grad_outputs=torch.ones_like(T), create_graph=True)[0]
        dT_dy = grad(T, y_t, grad_outputs=torch.ones_like(T), create_graph=True)[0]
        dT_dz = grad(T, z_t, grad_outputs=torch.ones_like(T), create_graph=True)[0]
        dT_dt = grad(T, t_t, grad_outputs=torch.ones_like(T), create_graph=True)[0]
        
        # Second derivatives
        d2T_dx2 = grad(dT_dx, x_t, grad_outputs=torch.ones_like(dT_dx), create_graph=True)[0]
        d2T_dy2 = grad(dT_dy, y_t, grad_outputs=torch.ones_like(dT_dy), create_graph=True)[0]
        d2T_dz2 = grad(dT_dz, z_t, grad_outputs=torch.ones_like(dT_dz), create_graph=True)[0]
        
        return T, dT_dt, dT_dx, dT_dy, dT_dz, d2T_dx2, d2T_dy2, d2T_dz2
    
    def pde_residual(self, model, x, y, z, t):
        """Compute PDE residual from Eq. (1) and (5)"""
        # Compute derivatives and temperature
        T, dT_dt, dT_dx, dT_dy, dT_dz, d2T_dx2, d2T_dy2, d2T_dz2 = \
            self.compute_derivatives(model, x, y, z, t)
        
        # Material properties
        rho = self.params['rho']
        Cp = self.specific_heat(T)
        k = self.thermal_conductivity(T)
        
        # Heat source term
        Q = self.laser_heat_source(x, y, z, t)
        
        # Laplacian term
        laplacian = d2T_dx2 + d2T_dy2 + d2T_dz2
        
        # Heat conduction equation residual (normalized)
        residual = (rho * Cp * dT_dt - k * laplacian - Q * self.Q_max) / self.Q_max
        
        return residual
    
    def ic_residual(self, model, x, y, z, t):
        """Initial condition residual from Eq. (2) and (6)"""
        inputs = torch.stack([x, y, z, t], dim=1)
        T = model(inputs)
        return (T - self.params['T0']) / self.T_ref
    
    def bc_residual(self, model, x, y, z, t):
        """Boundary condition residual from Eq. (3) and (7)"""
        # Compute derivatives and temperature
        T, _, dT_dx, dT_dy, dT_dz, _, _, _ = \
            self.compute_derivatives(model, x, y, z, t)
        
        # Boundary detection
        tol = 1e-4
        is_x_min = torch.abs(x) < tol
        is_x_max = torch.abs(x - self.Lx) < tol
        is_y_min = torch.abs(y) < tol
        is_y_max = torch.abs(y - self.Ly) < tol
        is_z_min = torch.abs(z) < tol
        is_z_max = torch.abs(z - self.Lz) < tol
        
        # Initialize residual
        bc_residual = torch.zeros_like(T)
        
        # Get material properties
        k = self.thermal_conductivity(T)
        h = self.params['h']
        epsilon = self.params['epsilon']
        T0 = self.params['T0']
        
        # x=0: Insulated (dT/dx = 0)
        bc_residual = torch.where(is_x_min, dT_dx, bc_residual)
        
        # x=Lx: Convection + radiation
        q_conv = h * (T - T0)
        q_rad = epsilon * self.sigma_sb * (T**4 - T0**4)
        bc_residual = torch.where(is_x_max, k*dT_dx + q_conv + q_rad, bc_residual)
        
        # y=0 and y=Ly: Insulated (dT/dy = 0)
        bc_residual = torch.where(is_y_min | is_y_max, dT_dy, bc_residual)
        
        # z=0: Insulated (dT/dz = 0)
        bc_residual = torch.where(is_z_min, dT_dz, bc_residual)
        
        # z=Lz: Convection + radiation
        bc_residual = torch.where(is_z_max, k*dT_dz + q_conv + q_rad, bc_residual)
        
        return bc_residual / self.Q_max  # Normalized

def generate_training_data(params, n_pde=20000, n_ic=30000, n_bc=10000, device='cpu'):
    """Generate training points with focused sampling around laser path"""
    Lx, Ly, Lz = params['Lx'], params['Ly'], params['Lz']
    t1, t2 = params['t1'], params['t2']
    t_max = t1 + t2
    v = params['v']
    
    # PDE points - focused sampling around laser path
    # Laser region (70%)
    n_laser = int(0.7 * n_pde)
    t_laser = torch.rand(n_laser, device=device).pow(2) * t1  # More early samples
    x_laser = v * t_laser + 0.0005 * torch.randn(n_laser, device=device)
    y_laser = Ly/2 + 0.001 * torch.randn(n_laser, device=device)
    z_laser = 0.0002 * torch.rand(n_laser, device=device).pow(3)
    
    # Surface region (20%)
    n_surface = int(0.2 * n_pde)
    x_surface = torch.rand(n_surface, device=device) * Lx
    y_surface = torch.rand(n_surface, device=device) * Ly
    z_surface = 0.0001 * torch.rand(n_surface, device=device).pow(4)
    t_surface = torch.rand(n_surface, device=device) * t_max
    
    # Uniform region (10%)
    n_uniform = n_pde - n_laser - n_surface
    x_uniform = torch.rand(n_uniform, device=device) * Lx
    y_uniform = torch.rand(n_uniform, device=device) * Ly
    z_uniform = torch.rand(n_uniform, device=device) * Lz
    t_uniform = torch.rand(n_uniform, device=device) * t_max
    
    # Combine PDE points
    x_pde = torch.cat([x_laser, x_surface, x_uniform])
    y_pde = torch.cat([y_laser, y_surface, y_uniform])
    z_pde = torch.cat([z_laser, z_surface, z_uniform])
    t_pde = torch.cat([t_laser, t_surface, t_uniform])
    X_pde = torch.stack([x_pde, y_pde, z_pde, t_pde], dim=1)
    
    # Initial condition points (t=0)
    x_ic = torch.rand(n_ic, device=device) * Lx
    y_ic = torch.rand(n_ic, device=device) * Ly
    z_ic = torch.rand(n_ic, device=device) * Lz
    t_ic = torch.zeros(n_ic, device=device)
    X_ic = torch.stack([x_ic, y_ic, z_ic, t_ic], dim=1)
    
    # Boundary condition points
    n_per_face = n_bc // 6  # 6 faces
    
    # Generate times for BC points
    t_bc = torch.rand(n_per_face, device=device) * t_max
    
    # x=0 and x=Lx faces
    x_bc1 = torch.zeros(n_per_face, device=device)
    x_bc2 = torch.ones(n_per_face, device=device) * Lx
    y_bc = torch.rand(2*n_per_face, device=device) * Ly
    z_bc = torch.rand(2*n_per_face, device=device) * Lz
    t_bc1 = t_bc.repeat(2)
    
    # y=0 and y=Ly faces
    x_bc3 = torch.rand(2*n_per_face, device=device) * Lx
    y_bc1 = torch.zeros(n_per_face, device=device)
    y_bc2 = torch.ones(n_per_face, device=device) * Ly
    z_bc1 = torch.rand(2*n_per_face, device=device) * Lz
    t_bc2 = t_bc.repeat(2)
    
    # z=0 and z=Lz faces
    x_bc4 = torch.rand(2*n_per_face, device=device) * Lx
    y_bc3 = torch.rand(2*n_per_face, device=device) * Ly
    z_bc2 = torch.zeros(n_per_face, device=device)
    z_bc3 = torch.ones(n_per_face, device=device) * Lz
    t_bc3 = t_bc.repeat(2)
    
    # Combine all BC points
    X_bc = torch.cat([
        torch.stack([x_bc1, y_bc[:n_per_face], z_bc[:n_per_face], t_bc[:n_per_face]], dim=1),
        torch.stack([x_bc2, y_bc[n_per_face:], z_bc[n_per_face:], t_bc[:n_per_face]], dim=1),
        torch.stack([x_bc3[:n_per_face], y_bc1, z_bc1[:n_per_face], t_bc[:n_per_face]], dim=1),
        torch.stack([x_bc3[n_per_face:], y_bc2, z_bc1[n_per_face:], t_bc[:n_per_face]], dim=1),
        torch.stack([x_bc4[:n_per_face], y_bc3[:n_per_face], z_bc2, t_bc[:n_per_face]], dim=1),
        torch.stack([x_bc4[n_per_face:], y_bc3[n_per_face:], z_bc3, t_bc[:n_per_face]], dim=1)
    ])
    
    return X_pde, X_ic, X_bc

def train_pinn(model, physics, X_pde, X_ic, X_bc, device, epochs=10000, lbfgs_epochs=16000):
    """Two-phase training as in the paper"""
    # Unpack coordinates
    x_pde, y_pde, z_pde, t_pde = X_pde[:,0], X_pde[:,1], X_pde[:,2], X_pde[:,3]
    x_ic, y_ic, z_ic, t_ic = X_ic[:,0], X_ic[:,1], X_ic[:,2], X_ic[:,3]
    x_bc, y_bc, z_bc, t_bc = X_bc[:,0], X_bc[:,1], X_bc[:,2], X_bc[:,3]
    
    # Loss weights (from paper)
    loss_weights = {'pde': 1.0, 'ic': 1.0, 'bc': 10.0}
    
    # Adam optimizer first
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    
    # Loss history
    history = {'total': [], 'pde': [], 'ic': [], 'bc': []}
    
    print("Starting Adam optimization...")
    for epoch in range(epochs):
        optimizer.zero_grad()
        
        # Compute all residuals
        loss_pde = torch.mean(physics.pde_residual(model, x_pde, y_pde, z_pde, t_pde)**2)
        loss_ic = torch.mean(physics.ic_residual(model, x_ic, y_ic, z_ic, t_ic)**2)
        loss_bc = torch.mean(physics.bc_residual(model, x_bc, y_bc, z_bc, t_bc)**2)
        
        # Weighted total loss
        total_loss = (loss_weights['pde'] * loss_pde + 
                     loss_weights['ic'] * loss_ic + 
                     loss_weights['bc'] * loss_bc)
        
        # Backpropagation
        total_loss.backward()
        optimizer.step()
        
        # Record history
        history['total'].append(total_loss.item())
        history['pde'].append(loss_pde.item())
        history['ic'].append(loss_ic.item())
        history['bc'].append(loss_bc.item())
        
        if (epoch+1) % 1000 == 0:
            print(f"Epoch {epoch+1}/{epochs}: Loss={total_loss.item():.3e} "
                  f"(PDE={loss_pde.item():.3e}, IC={loss_ic.item():.3e}, BC={loss_bc.item():.3e})")
    
    # L-BFGS optimization
    if lbfgs_epochs > 0:
        print("\nStarting L-BFGS optimization...")
        optimizer = optim.LBFGS(model.parameters(), 
                              max_iter=lbfgs_epochs,
                              history_size=100,
                              line_search_fn='strong_wolfe')
        
        def closure():
            optimizer.zero_grad()
            loss_pde = torch.mean(physics.pde_residual(model, x_pde, y_pde, z_pde, t_pde)**2)
            loss_ic = torch.mean(physics.ic_residual(model, x_ic, y_ic, z_ic, t_ic)**2)
            loss_bc = torch.mean(physics.bc_residual(model, x_bc, y_bc, z_bc, t_bc)**2)
            total_loss = (loss_weights['pde'] * loss_pde + 
                         loss_weights['ic'] * loss_ic + 
                         loss_weights['bc'] * loss_bc)
            total_loss.backward()
            
            # Record history
            history['total'].append(total_loss.item())
            history['pde'].append(loss_pde.item())
            history['ic'].append(loss_ic.item())
            history['bc'].append(loss_bc.item())
            
            if len(history['total']) % 1000 == 0:
                print(f"L-BFGS Iter {len(history['total'])}: Loss={total_loss.item():.3e}")
            return total_loss
        
        optimizer.step(closure)
    
    return history

def plot_temperature_field(model, physics, time, save_path=None, plane='xy'):
    """Visualize temperature field at given time"""
    model.eval()
    device = next(model.parameters()).device
    
    # Create grid
    n_points = 100
    if plane == 'xy':
        # Top surface (z=0)
        x = torch.linspace(0, physics.Lx, n_points, device=device)
        y = torch.linspace(0, physics.Ly, n_points, device=device)
        X, Y = torch.meshgrid(x, y, indexing='ij')
        Z = torch.zeros_like(X)
        xlabel, ylabel = 'X (m)', 'Y (m)'
    elif plane == 'xz':
        # Vertical slice (y=Ly/2)
        x = torch.linspace(0, physics.Lx, n_points, device=device)
        z = torch.linspace(0, physics.Lz, n_points, device=device)
        X, Z = torch.meshgrid(x, z, indexing='ij')
        Y = torch.ones_like(X) * physics.Ly / 2
        xlabel, ylabel = 'X (m)', 'Z (m)'
    else:
        raise ValueError("plane must be 'xy' or 'xz'")
    
    # Flatten grid and add time
    grid_points = torch.stack([X.flatten(), Y.flatten(), Z.flatten(), 
                             torch.ones_like(X.flatten()) * time], dim=1)
    
    # Predict temperatures
    with torch.no_grad():
        T = model(grid_points).cpu().numpy().reshape(X.shape)
    
    # Plot
    plt.figure(figsize=(10, 8))
    plt.pcolormesh(X.cpu().numpy(), Y.cpu().numpy(), T, shading='auto', cmap='hot')
    plt.colorbar(label='Temperature (K)')
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(f'Temperature Field at t={time:.2f}s (plane={plane})')
    
    # Add laser position if in deposition phase
    if time <= physics.t1 and plane == 'xy':
        laser_x = physics.params['v'] * time
        laser_y = physics.Ly / 2
        plt.plot(laser_x, laser_y, 'wo', markersize=8, label='Laser position')
        plt.legend()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

def main():
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # Parameters from Table 2 in the paper
    params = {
        'rho': 7780.0,                # Density (kg/m^3)
        'eta': 0.75,                  # Laser absorption coefficient
        'P': 2000.0,                  # Laser power (W)
        'v': 8.0e-3,                  # Scanning speed (m/s)
        'Ra': 3.0e-3,                 # Laser spot radius in x (m)
        'Rb': 3.0e-3,                 # Laser spot radius in y (m)
        'Rc': 1.0e-3,                 # Laser spot radius in z (m)
        'h': 20.0,                    # Convection coefficient (W/(m^2·K))
        'epsilon': 0.85,              # Emissivity
        'T0': 293.15,                 # Initial/ambient temperature (K)
        'Tm': 1730.0,                 # Melting temperature (K)
        'Ts': 1690.0,                 # Solidus temperature (K)
        'Lx': 0.04,                   # Domain length in x (m)
        'Ly': 0.02,                   # Domain width in y (m)
        'Lz': 0.005,                  # Domain height in z (m)
        't1': 2.0,                    # Deposition time (s)
        't2': 10.0                    # Cooling time (s)
    }
    
    # Initialize model
    model = PINN_LMD().to(device)
    
    # Set scaling factors
    model.set_scaling_factors(params['Lx'], params['Ly'], params['Lz'], 
                            params['t1'], params['t2'], 3000.0)
    
    # Set input normalization (mean and std of coordinates)
    input_mean = torch.tensor([params['Lx']/2, params['Ly']/2, 
                              params['Lz']/2, params['t1']/2])
    input_std = torch.tensor([params['Lx'], params['Ly'], 
                            params['Lz'], params['t1'] + params['t2']])
    model.set_input_stats(input_mean, input_std)
    
    # Initialize physics
    physics = LMDPhysics(params)
    
    # Generate training data (same counts as paper)
    print("Generating training data...")
    X_pde, X_ic, X_bc = generate_training_data(
        params, n_pde=20000, n_ic=30000, n_bc=10000, device=device)
    
    # Train the model
    print("Starting training...")
    history = train_pinn(model, physics, X_pde, X_ic, X_bc, 
                        device, epochs=10000, lbfgs_epochs=16000)
    
    # Plot loss history
    plt.figure(figsize=(10,6))
    plt.semilogy(history['total'], label='Total Loss')
    plt.semilogy(history['pde'], label='PDE Loss')
    plt.semilogy(history['ic'], label='IC Loss')
    plt.semilogy(history['bc'], label='BC Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss (log scale)')
    plt.title('Training Loss History')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    # Visualize results at key time points
    for t in [0.5, 1.0, 2.0]:
        plot_temperature_field(model, physics, t, plane='xy')
        plot_temperature_field(model, physics, t, plane='xz')

if __name__ == "__main__":
    main()
